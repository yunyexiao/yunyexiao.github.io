---
layout:	post
title:	"Machine Learning Notes: Lecture 3-4"
description: "Andrew Ng Machine Learning Notes for Lecture 3-4: Linear Regression With Multiple Variable"
date:	2019-07-14
tags:	["Machine Learning", "Andrew Ng"]
---

# 3. Linear Algebra
Just the knowledges about the concept of matrix and vector and the addition, scaler, multiplication, inversion and transposition operations are needed. No more introduction. It is quite simple.


# 4. Linear Regression with Multi-vars

## 4.1 Model
The idea is to use matrix/vector to represent the dataset and arguments.

Suppose our training set has $$n$$ features, $$m$$ rows of data and only one column of output values. We denote $$x^{(i)}$$ as a vector holds the $$i^{th}$$ row of data and $$x^{(i)}_j$$ as the value of the $$j^{th}$$ feature in that vector. Then the hypothesis function would be:

$$h_\theta{(x)} = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n$$

Define $$x_0 = 1$$, we can rewrite it to:

$$h_\theta{(x)} = \sum_{j=0}^n \theta_i x_i$$

Define $$x = \begin{bmatrix}x_0\\x_1\\...\\x_n\end{bmatrix}$$ and $$\theta = \begin{bmatrix}\theta_0\\\theta_1\\...\\\theta_n\end{bmatrix}$$, we can rewrite it to:

$$h_\theta{(x)} = \theta^T x$$

## 4.2 Cost Function
The cost function is the same as that in Section 2.2.

$$J(\theta) = \frac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$$

## 4.3 Gradient Descent
Using vector denotation, we can rewrite the update rules to:

$$\theta_j := \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}, j = 0,1,...,n$$

### 4.3.1 Feature Scaling
There is a problem with gradient descent: when the ranges of different features differ too much, the shape of the cost function would be much skewed so that the gradient descent would take much long to converge. For example, if $$x_1 \in [0,2000]$$ and $$x_2 \in [1,5]$$, the picture of the coutour of the cost function would be like below:

![Skewed Contour]({{ 'assets/img/post_img/2019-07-14-SkewedContour.png' | relative_url }})

To solve this problem, we have to scale our feature ranges to a similar range like $$[-1, 1]$$. E.g. we can define $$x_1 := \frac{x_1}{2000}$$ and $$x_2 := \frac{x_2}{5}$$ to similarify their ranges so that the coutour of the cost function would be rounder like the picture below and the gradient descent would converge more quickly.

![Round Contour]({{ 'assets/img/post_img/2019-07-14-RoundContour.png' | relative_url }})

The range to scale to should not be too large (E.g. $$[-100,100]$$) nor too small (E.g. $$[-0.0001,0.0001]$$). $$[-1,1]$$ may be a good choice, because $$x_0=1$$ is in this range.

### 4.3.2 Mean Normalization
We should also try to reduce the mean of each feature to 0. Along with feature scaling we talked about above, we can define:

$$x_i := \frac{x_i - \mu_i}{s_i}$$,

where $$\mu_i$$ is the mean of the feature and $$s_i$$ is the range length or standard deviation of the feature.

### 4.3.3 Learning Rate $$\alpha$$
There are some practices to know about the determination of learning rate.

Firstly we have to make sure our gradient descent is working correctly. We can define a thredshold like 0.001 and if the difference of the cost function $$J(\theta)$$ between two ajacent iterations get smaller than that thredshold, we say it converged. But the thredshold would be difficult to define. So another way: we draw the plot of $$J(\theta)$$ with the number of iterations like below:

![Gradient Iteration Plot]({{ 'assets/img/post_img/2019-07-14-GradientIterationPlot-Converging.png' | relative_url }})

We can intuitively find whether it is converging on the plot. The diverging plot would be like below:

![Gradient Iteration Plot Diverging 1]({{ 'assets/img/post_img/2019-07-14-GradientIterationPlot-Diverging-1.png' | relative_url }})
![Gradient Iteration Plot Diverging 2]({{ 'assets/img/post_img/2019-07-14-GradientIterationPlot-Diverging-2.png' | relative_url }})

In such cases, the reason for divergence is that the learning rate $$\alpha$$ is too large. (Also, if it is too small, it will take much long to converge.) Use a smaller $$\alpha$$ and try gradient descent again. Actually, for sufficient $$\alpha$$, $$J(\theta)$$ should decrease on each iteration.

## 4.4 Choice of Features

### 4.4.1 Example: house prices prediction
We have a set of data of houses with their frontages, depths and prices and our goal is to predict a house's price according to its frontage and depth. Should we suppose that the hypothesis function $$h_\theta(x) = \theta_0 + \theta_1 frontage + \theta_2 depth$$? We can have another choice: use area = frontage * depth. Area makes more sense than frontage and depth of a house. So $$h_\theta(x) = \theta_0 + \theta_1 area$$ is more simple and make more sense in this case.

### 4.4.2 Polynomial Regression
We might not suppose that the relation between the price of a house and its area is linear. Actually, we might suppose that $$price = \theta_0 + \theta_1 area + \theta_2 area^2 + \theta_3 area^3$$. Polynomials make more sense. In this case, we can assume $$x_1 = area$$, $$x_2 = area^2$$, and $$x_3 = area^3$$, and we get: $$h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_3$$. Then we can use gradient descent to do the regression. The selection of features is flexible.

## 4.5 Normal Equation
Another method to calculate $$\theta$$ which can make the minimum value of the cost function.

Define $$x_0^{(i)} = 1$$, $$x^{(i)} = \begin{bmatrix}x_0^{(i)}\\x_1^{(i)}\\...\\x_n^{(i)}\end{bmatrix}$$, and then $$X = \begin{bmatrix}(x^{1})^T\\(x^{2})^T\\...\\(x^{m})^T\end{bmatrix}$$. $$x^{(i)}$$ represents the $$i^{th}$$ row of the training set, and $$X$$ represents the training set. Also, $$y = \begin{bmatrix}y^{(1)}\\y^{(2)}\\...\\y^{(m)}\end{bmatrix}$$. Then we can calculate the vector $$\theta$$ by solving the equation set: $$\frac{\partial}{\partial \theta_i} J_\theta(x) = 0$$ for $$i = 0,1,...,n$$. So the answer would be (proof is easy and thus skipped):

$$\theta = (X^T X)^{-1} X^T y$$

There may be a **rare** problem: what if $$X^T X$$ is not invertible? Actually, use `pinv(M)` function in Octave will always be right. The reason why $$X^T X$$ is not invertible mainly lies in the following 2 occasions:

1. There are redundant features (l.e. linear relation between several features). In this case, just remove those redundant features.
2. The number of features $$n$$ is greater than the size of the training set $$m$$. In this case, try to delete some features, or use *regularization*.

## 4.6 Comparison
For *Gradient Descent*:
* Needs to choose learning rate $$\alpha$$.
* Needs many iterations.
* Is scalable. Works well even when $$n$$ is very large.

For *Normal Equation*:
* No need to choose $$\alpha$$.
* No need to iterate.
* Need to compute $$(X^T X)^{-1}$$ whose time complexity is $$O(n^3)$$.
* Slow when $$n$$ is large.
