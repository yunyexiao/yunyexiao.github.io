---
layout:	post
title:	"Machine Learning Notes: Lecture 8-9"
description: "Andrew Ng Machine Learning Notes for Lecture 8-9: Neural Network"
date:	2019-07-15
tags:	["Machine Learning", "Andrew Ng"]
---

# 8. Neural Network Representation

## 8.1 Neuron Model
Quite a lot of times, we have to do machine learning on a very huge number of features. E.g. for a 50px\*50px picture, there are 2500 pixels and 7500 features in RGB pixels. Using linear regression or logistic regression is too inefficient. So Neural Network occurs.

It came into existence at around 1980s, and was gaining popularity at that time. And because of the lack of computing resources at that time, it lost its attraction. But nowadays, with more and more computing resources and techneques, it resurged.

The simplest logistic neuron model is like below:

![Logistic Neuron Model]({{ 'assets/img/post_img/2019-07-15-LogisticNeuron.png' | relative_url }})

In this picture, $$x_1, x_2, x_3$$ are inputs, the orange circle in the middle is the neuron body, and the $$h_\theta(x)$$ is called the *activation function*. Here we left out the input $$x_0$$ for convenience reasons, but the input unit $$x_0$$ is called the *Bias Unit*. The neuron body processes the input and uses an activation function to process it. Of course, $$h_\theta(x) = \frac{1}{1+e^{-\theta^T x}}$$. In the function, $$\theta$$ is called *parameters*, or *weights*. 

Here is a simple neural network:

![Simple Neural Network]({{ 'assets/img/post_img/2019-07-15-SimpleNeuralNetwork.png' | relative_url }})

Also, the bias units are omitted. Each column of units is called a *layer*. The first layer is called *Input Layer*, the last layer is called *Output Layer*, and the layers in between is called *Hidden Layers*. In default, the numbers of units in different hidden layers are the same.

Here we denote $$a_i^{(j)}$$ as the "activation" output of unit $$i$$ in layer $$j$$, and $$\Theta^{(j)}$$ as the matrix of weights controlling function mapping from layer $$j$$ to layer $$j+1$$. So

$$
\begin{array}{ll}
    a_1^{(2)} = g(\Theta_{10}^{(1)} x_0 + \Theta_{11}^{(1)} x_1 + \Theta_{12}^{(1)} x_2 + \Theta_{13}^{(1)} x_3)\\
    a_2^{(2)} = g(\Theta_{20}^{(1)} x_0 + \Theta_{21}^{(1)} x_1 + \Theta_{22}^{(1)} x_2 + \Theta_{23}^{(1)} x_3)\\
    a_3^{(2)} = g(\Theta_{30}^{(1)} x_0 + \Theta_{31}^{(1)} x_1 + \Theta_{32}^{(1)} x_2 + \Theta_{33}^{(1)} x_3)\\
    h_\Theta(x) = a_1^{(3)} = g(\Theta_{10}^{(2)} a_0^{(2)} + \Theta_{11}^{(2)} a_1^{(2)} + \Theta_{12}^{(2)} a_2^{(2)} + \Theta_{13}^{(2)} a_3^{(3)})
\end{array}
$$

where $$g(z)$$ is the sigmoid function. Using matrix representation, we can rewrite it to:

$$
\begin{array}{ll}
    a^{(2)} = g(\Theta^{(1)} x)\\
    h_\Theta(x) = a^{(3)} = g(\Theta^{(2)} a^{(2)})
\end{array}
$$

## 8.2 Example: $$x_1$$ XNOR $$x_2$$
Firstly, we try to solve $$x_1$$ AND $$x_2$$. We use the following model:

![Neural Network AND]({{ 'assets/img/post_img/2019-07-15-NeuralNetwork-AND.png' | relative_url }})

The hypotheses function is $$h_\Theta(x) = g(-30 + 20x_1 + 20x_2)$$. The sigmoid function $$g(z)$$ has the following properties:
* When $$z < -4.0$$, $$g(z)$$ is close to 0.
* When $$z > 4.0$$, $$g(z)$$ is close to 1.

So here comes the result of our hypothese function:

|$$x_1$$|$$x_2$$|$$h_\Theta(x)$$|
|:---	|:---	|:---		|
|0	|0	|0		|
|0	|1	|0		|
|1	|0	|0		|
|1	|1	|1		|

It works perfectly.

Similarly, we can solve $$x_1$$ OR $$x_2$$ by $$h_\Theta(x) = g(-10 + 20x_1 + 20x_2)$$, and solve $$x_1$$ NOR $$x_2$$ by $$h_\Theta(x) = g(10 - 20x_1 - 20x_2)$$. And finally, we try to solve $$x_1$$ XNOR $$x_2$$. Because $$x_1$$ XNOR $$x_2$$ = ($$x_1$$ AND $$x_2$$) OR ($$x_1$$ NOR $$x_2$$),
so we define 

$$
\begin{array}{ll}
\Theta^{(1)} = \begin{bmatrix}-30 & 20 & 20\\10 & -20 & -20\end{bmatrix}\\
\Theta^{(2)} = \begin{bmatrix}-10 & 20 & 20\end{bmatrix}
\end{array}
$$

And the model is like below:

![Neural Network XNOR]({{ 'assets/img/post_img/2019-07-15-NeuralNetwork-XNOR.png' | relative_url }})

We can easily prove that this hypotheses works well by drawing a truth table for it.

## 8.3 Multiclass Neural Network
To handle multiclass classification, our neural network should have multiple output units, with the output of each unit representing the probability of a certain class. So our output will become a vector whose dimension is the same as the number of classes. As our ouput format has changed from a number to a vector, our $$y^{(i)}$$ should also change that way. E.g. if we have 4 classes, say A, B, C, and D, then if $$x^{(i)}$$ is of class A, then $$y^{(i)} = \begin{bmatrix}1\\0\\0\\0\end{bmatrix}$$. The neural network will be like the following:

![Multiclass Neural Network]({{ 'assets/img/post_img/2019-07-15-MulticlassNeuralNetwork.png' | relative_url }})

# 9. Neural Network Learning

## 9.1 Cost Function
Denote $$L$$ as the number of layers in the network, and $$s_l$$ as the number of units in layer $$l$$. Suppose we have $$K$$ ouput units, and denote $$(h_\Theta(x^{(i)}))_k$$ as the $$k^{th}$$ element in the output vector, then our cost function is:

$$
J(\Theta) = -\frac{1}{m} [\sum_{i=1}^m \sum_{k=1}^K Cost_k(x^{(i)})] + \frac{\lambda}{2m} \sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} (\Theta_{ji}^l)^2
$$

, where $$Cost_k(x^{(i)}) = y_k^{(i)} log(h_\Theta(x^{(i)}))_k + (1 - y_k^{(i)}) log(1 - (h_\Theta(x^{(i)}))_k)$$.

## 9.2 Back Propagation
Denote $$\delta_j^{(l)}$$ as the error of node $$j$$ in layer $$l$$. For each output unit, we define 

$$\delta^{(L)} = a^{(L)} - y$$ 

where $$a$$ is the activation value (a vector) of a certain layer, i.e. $$h_\Theta(x)$$. Then we define 

$$\delta^{(l)} = (\Theta^{(l)})^T \delta^{(l+1)} .* g'(z^{(l)}), i=2,3,...,L-1$$

where $$g(z)$$ is the sigmoid function and $$z = \Theta^T x$$.

Below is the back propagation algorithm:

1. Set $$\Delta_{ij}^{(l)} = 0$$ for all $$i,j,l$$.
2. For $$i = 1$$ to $$m$$:
    1. Set $$a^{(1)} = x^{(i)}$$
    2. Perform forward propagation to compute $$a^{(l)}$$ for $$l = 2,3,...,L$$
    3. Use $$y^{(i)}$$ to compute $$\delta^{(L)}$$
    4. Compute $$\delta^{(l)}$$ for $$l = L-1, L-2,...,2$$
    5. $$\Delta_{ij}^{(l)} := \Delta_{ij}^{(l)} + a_j^{(l)} \delta_i^{(l+1)}$$ or $$\Delta^{(l)} := \Delta^{(l)} + \delta^{(i+1)} (a^{l})^T$$
3. Compute matrix $$D^{(l)}$$ for $$l = 1,2,...,L$$.
    * $$D_{ij}^{(l)} := \frac{1}{m} \Delta_{ij}^{(l)}$$ if $$j = 0$$
    * $$D_{ij}^{(l)} := \frac{1}{m} \Delta_{ij}^{(l)} + \lambda \Theta_{ij}^{(l)}$$ if $$j \geq 1$$

And it turns out that $$D_{ij}^{(l)} = \frac{\partial}{\partial \Theta_{ij}^{(l)}} J(\Theta)$$. 

Below are some practices on its implementation.

### 9.2.1 Gradient Checking
As this algorithm is somewhat complex, in order to check whether our implementation is correct, we introduce the *Gradient Checking*. The idea of Gradient Checking is quite simple: $$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta) \approx \frac{J(\Theta + \epsilon) - J(\Theta - \epsilon)}{2 \epsilon}$$. So we just have to check whether $$D_{ij}^{(l)}$$ is approximately equal to that expression, and if it is, you can turn off gradient checking and use that model to learn. Gradient checking is often quite slow, so do not retain it in your code.

### 9.2.2 Random Initialization
For linear or logistic regression, we can initialize our parameter $$\theta$$ to zeros. But in neural networks like the following picture:

![Zero Initialization]({{ 'assets/img/post_img/2019-07-17-ZeroInitialization.png' | relative_url }})

if $$\Theta^{(l)} = zeros$$ for each $$l=1,2,...,L$$, what we can get is that $$a_1^{(2)} = a_2^{(2)}$$, $$\delta_1^{(2)} = \delta_2^{(2)}$$, $$D_{1j}^{(1)} = D_{2j}^{(1)}$$ for $$j=1,2$$, and thus $$a_1^{(2)}$$ will always be identical to $$a_2^{(2)}$$. This neural network is considered to be less useful because all of its hidden units are identical indeed.

As a result, we introduce random initialization. We want each $$\Theta_{ij}^{(l)}$$ to be a random value in the range of $$[-\epsilon, \epsilon]$$. E.g. we can initialize each to $$rand \times 2\epsilon - \epsilon$$
